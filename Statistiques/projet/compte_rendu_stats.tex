\documentclass[a4paper,11pt]{article}

\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[francais]{babel}
\usepackage{amsmath,amssymb}
\usepackage{fullpage}
\usepackage{xspace}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{mathrsfs}
\usepackage[usenames,dvipsnames]{color}
\usepackage{url}

\lstset{basicstyle=\small\tt,
  keywordstyle=\bfseries\color{Orchid},
  stringstyle=\it\color{Tan},
  commentstyle=\it\color{LimeGreen},
  showstringspaces=false}

\newtheorem{exo1}{Question}
\newtheorem{exo2}{Question}
\newtheorem{exo3}{Question}
\newtheorem{exo4}{Question}

\newcommand{\dx}{\,dx}
\newcommand{\ito}{,\dotsc,}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Poly}[1]{\mathcal{P}_{#1}}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\pars}[1]{\left(#1\right)}
\newcommand{\bigpars}[1]{\bigl(#1\bigr)}
\newcommand{\set}[1]{\left\{#1\right\}}

\title{TP Statistiques : Compte-rendu}
\author{Michel Yoeung, Charles-Frédérick Amaudruz, Alexandre Berrada (ENSIMAG - 1A - Groupe 2)}
\date{Avril 2018}

\begin{document}

\maketitle

%======================================
\section{Première stratégie.}
%======================================

\begin{exo1} \ \\ \\
\[
  \forall i = 1,...,n, X_{i} = \left\{
                                  \begin{array}{ll}
                                    1 & \quad \mathrm{\text{si le $i^{eme}$ poisson est bagué}} \\
                                    0 & \quad \mathrm{sinon} \\
                                  \end{array}
                                \right.
\]
De plus, les résultats des pêches successives sont indépendants et la probabilité que le $i^{eme}$ poisson soit bagué est $p=\frac{n_{0}}{\theta}$. \ \\
Donc les $X_{i}$ sont indépendants et identiques (iid) car suivent tous une loi de Bernoulli de paramètre de succès $p=\frac{n_{0}}{\theta}$. \ \\
Soit $\theta=1000$ et $n_{0}=50$. On choisit $n=60$ pour notre simulation sur R. \ \\
On obtient l'échantillon de données suivant :
\begin{figure}[h]
\includegraphics[scale=0.45]{images/Q1_1_donnees.png}
\end{figure} \ \\
On calcule ensuite sur R les moyennes et les variances (empiriques et théoriques) :
\begin{figure}[h]
\includegraphics[scale=0.7]{images/Q1_1.png}
\end{figure} \ \\
On constate que pour ce jeu de données la moyenne empirique est assez proche de la moyenne théorique et de même pour les variances.
\end{exo1}

\begin{exo1} \ \\ \\
$T$ est une variable aléatoire qui compte le nombre de poissons bagués parmi les $n$ poissons pêchés donc $T=\sum\limits_{i=1}^{n}X_{i}$ avec $X_{i}$ qui suit une loi de Bernoulli. \ \\
Donc $T$ suit une loi binomiale de paramètres $n$ et $p=\frac{n_{0}}{\theta}$. \ \\
On donne ainsi avec R $t$ le nombre de poissons pêchés sur notre échantillon de données :
\begin{figure}[h]
\includegraphics[scale=0.7]{images/Q1_2.png}
\end{figure} \ \\
\end{exo1}

\begin{exo1} \ \\ \\
Estimateur des moments : \ \\
Soit $\overline{X}_n$ la moyenne empirique, \ \\
\begin{equation}
\begin{aligned}
E[X] \simeq \overline{X}_n & \Rightarrow p \simeq \frac{1}{n}\sum_{i=1}^{n} x_{i} \ \\
& \Rightarrow \frac{n_{0}}{\theta} \simeq \frac{1}{n}\sum_{i=1}^{n} x_{i} \ \\
& \Rightarrow \theta \simeq \frac{n_{0}*n}{\sum_{i=1}^{n} x_{i}} \ \\
\end{aligned}
\end{equation} \ \\
Donc l'estimateur des moments (d'ordre 1) vaut $\tilde{\theta_{n}}=\frac{n_{0}*n}{\sum_{i=1}^{n} x_{i}}$. \ \\ \\
Estimateur de maximum de vraisemblance : \ \\ \\
\begin{equation}
\begin{aligned}
\mathscr{L}(X_{1}=x_{1},...,X_{n}=x_{n}, \theta) & = \prod_{i=1}^{n}\textsc{P}(X_{i}=x_{i}, \theta) \ \\
& = p^{\sum_{i=1}^{n} x_{i}}(1-p)^{n-\sum_{i=1}^{n} x_{i}} \ \\ 
& = (\frac{n_{0}}{\theta})^{\sum_{i=1}^{n}
x_{i}}(1-\frac{n_{0}}{\theta})^{n-\sum_{i=1}^{n} x_{i}} \ \\
\end{aligned}
\end{equation} \ \\
$\ln(\mathscr{L}(X_{1}=x_{1},...,X_{n}=x_{n}, \theta)) = (\sum\limits_{i=1}^{n}x_{i})(\ln(n_{0})-\ln(\theta))+(n-\sum\limits_{i=1}^{n} x_{i})\ln(1-\frac{n_{0}}{\theta})$ \ \\ \\
En dérivant par rapport à $\theta$ : \ \\
\begin{equation}
\begin{aligned}
\frac{\partial\,\ln(\mathscr{L}(X_{1}=x_{1},...,X_{n}=x_{n}, \theta))}{\partial\,\theta} & = -(\sum_{i=1}^{n} x_{i})\frac{1}{\theta}+(n-\sum_{i=1}^{n} x_{i})\frac{\frac{n_{0}}{\theta^{2}}}{1-\frac{n_{0}}{\theta}} \ \\
& = -(\sum_{i=1}^{n} x_{i})\frac{1}{\theta}+(n-\sum_{i=1}^{n} x_{i})\frac{n_{0}}{\theta^{2}-\theta n_{0}} \ \\
& = 0 \Rightarrow \theta=\frac{n_{0}*n}{\sum_{i=1}^{n} x_{i}}
\end{aligned}
\end{equation} \ \\
Donc l'estimateur de maximum de vraisemblance vaut $\hat{\theta_{n}}=\frac{n_{0}*n}{\sum_{i=1}^{n} x_{i}}$. \ \\
Donc ces deux estimateurs sont confondus. \ \\
On calcule ainsi sur R la valeur de ces estimateurs sur notre échantillon de données : \ \\
\begin{figure}[h]
\includegraphics[scale=0.7]{images/Q1_3.png}
\end{figure} \ \\
Sur l'échantillon simulée, on observe un estimateur de $\theta$ qui vaut $750$ soit $25\%$ de moins que la vraie valeur de $\theta$ pour la simulation ($1000$). \ \\
Cet estimateur n'est pas très précis.
\end{exo1}

\begin{exo1} \ \\ \\
intervalle de confiance exact de seuil $\alpha$ pour $\theta$ : \ \\
On a $p=\frac{n_{0}}{\theta} \Rightarrow \theta=\frac{n_{0}}{p}$ donc en estimant $p$ (avec la formule du cours), on obtient directement une estimation de $\theta$.
\begin{equation}
\begin{aligned}
\left[ n_{0}(1+\frac{n-T}{T+1}f_{2(n-T),2(T+1),1-\frac{\alpha}{2}}),n_{0}(1+\frac{n-T+1}{T}f_{2(n-T+1),2T,\frac{\alpha}{2}})\right]
\end{aligned}
\end{equation} \ \\
avec $T=n\overline{X}_{n}=\sum\limits_{i=1}^{n} x_{i}$ et $f_{\nu_{1},\nu_{2},\alpha} = F_{\mathscr{F}}^{-1}(1-\alpha,\nu_{1},\nu_{2})$, $F_{\mathscr{F}}^{-1}$ étant ici la fonction quantile de la loi de Fisher-Snedecor. \ \\
intervalle de confiance asymptotique de seuil $\alpha$ pour $\theta$ : \ \\
On obtient l'intervalle associée avec la même démarche que précédement.
\begin{equation}
\begin{aligned}
\left[ \frac{n_{0}}{\overline{X_{n}}+u_{\alpha}\sqrt{\frac{\overline{X_{n}}(1-\overline{X_{n}})}{n}}},\frac{n_{0}}{\overline{X_{n}}-u_{\alpha}\sqrt{\frac{\overline{X_{n}}(1-\overline{X_{n}})}{n}}}\right]
\end{aligned}
\end{equation} \ \\
avec $u_{\alpha}=F_{\mathscr{N}}^{-1}(1-\frac{\alpha}{2})$, $F_{\mathscr{N}}^{-1}$ étant ici la fonction quantile de la loi normale. \ \\
On calcule ainsi ces intervalles de confiance (exacts puis asymptotiques) associés aux valeurs de nos paramètres fixés sur R pour les différentes valeurs de $\alpha$ spécifiées dans l'énoncé :
\begin{figure}[h]
\includegraphics[scale=0.7]{images/Q1_4_exact.png}
\end{figure}
\begin{figure}[h]
\includegraphics[scale=0.7]{images/Q1_4_asymp.png}
\end{figure} \ \\
On remarque que les intervalles exacts fournissent un encadrement plus précis de la vraie valeur de $\theta$ que les intervalles asymptotiques ce qui semble logique car les intervalles symptotiques sont plus efficaces pour un $n$ très grand, or ici on a fixé $n=60$ seulement.
\end{exo1}

\begin{exo1} \ \\ \\
$\textsc{P}(\hat{\theta}_{n}=+\infty) = \textsc{P}(\frac{n_{0}*n}{\sum\limits_{i=1}^{n} x_{i}}=+\infty) = \textsc{P}(\sum_{i=1}^{n} x_{i}=0) = \textsc{P}(T=0) = (1-p)^n = (1-\frac{n_{0}}{\theta})^n$ \ \\
Cet estimateur n'est pas convergent. \ \\
$Biais(\hat{\theta}_{n}) = E[\hat{\theta_{n}}]-\theta$ \ \\
Comme $\hat{\theta}_{n}$ a une probabilité non nulle de valoir $+\infty$ alors $E[\hat{\theta}_{n}]=+\infty \Rightarrow $E[$\hat{\theta}_{n}$]$-\theta = +\infty$ (car $\theta$ est une constante) $\Rightarrow $Biais$(\hat{\theta}_{n}) = +\infty$. \ \\
Donc on peut en déduire que le biais de cet estimateur vaut $+\infty$.
Sur notre échantillon de données, on peut calculer la probabilité $\textsc{P}(\hat{\theta}_{n}=+\infty)$ :
\begin{figure}[h]
\includegraphics[scale=0.7]{images/Q1_5.png}
\end{figure} \ \\
\end{exo1}

\begin{exo1} \ \\ \\
\begin{equation}
\begin{aligned}
\textsc{P}(\hat{\theta}_{n}=+\infty) > \frac{1}{2} & \Rightarrow (1-\frac{n_{0}}{\theta})^{n} > \frac{1}{2} \ \\
& \Rightarrow n\ln(1-\frac{n_{0}}{\theta}) > \ln(\frac{1}{2}) \ \\
& \Rightarrow n < -\frac{\ln(2)}{\ln(1-\frac{n_{0}}{\theta})} \ \\
& \Rightarrow n \leq \lfloor-\frac{\ln(2)}{\ln(1-\frac{n_{0}}{\theta})}\rfloor
\end{aligned}
\end{equation} \ \\
Toujours avec notre échantillon de données, on calcule sur R cette valeur de n pour laquelle la probabilité $\textsc{P}(\hat{\theta_{n}}=+\infty)$ :
\begin{figure}[h]
\includegraphics[scale=0.5]{images/Q1_6.png}
\end{figure} \ \\
\end{exo1}

\newpage

%======================================
\section{Deuxième stratégie.}
%======================================

\begin{exo2} \ \\ \\
    $\forall j = 1,...,m , Y_{j}$ représente le nombre de poissons pêchés entre le $j^{eme}$
    poisson bagué et le $(j+1)^{eme}$.
On répète successivement l'expérience "on pêche un poisson" jusqu'à ce qu'il soit bagué,
de probabilité $\frac{n_0}{\theta}$. Les $Y_i$ suivent donc tous une loi géométrique de paramètre
$\frac{n_0}{\theta}$.\ \\D'autre part, ils concernent des pêches différentes, donc ils sont
de plus indépendants.\ \\
\includegraphics[scale=0.5]{images/Q2_1_1.png}
\\ \\
En théorie, la moyenne et la variance d'une loi géométrique $G(p)$ sont données par $\frac{1}{p}$ et $\frac{1-p}{p^2}$, soit pour $n_0 = 50$ et $\theta = 1000$, $\mathbb{E}(Y) = 20$ et Var$(Y) = 380$. \ 
Pour notre échantillon, nous calculons:\ \\
\includegraphics[scale=0.5]{images/Q2_1_2.png} \ \\
Les résultats que nous obtenons sont proches des résultats théoriques.
\end{exo2}

\begin{exo2} \ \\ \\
En notant N le nombre de poissons pêchés, on a $N = \sum\limits_{j=1}^{m} Y_j$\ \\
$\Omega(N) = [| m, +\infty [|$ \ \\
Soit $n \geqslant m$, et $x = (x_1, ..., x_n) \in (N = n).$ \ \\
On sait que $x_n = 1$ (le dernier poisson pêché est bagué par définition de $Y_n$), m-1 des n-1 autres pêches sont des poissons bagués. Ceci justifie que $\#(N=n) = \begin{pmatrix} n-1 \\ m-1\end{pmatrix}$. \ \\
Chacun des éléments de $(N=n)$ étant de probabilité $(\frac{n_0}{\theta})^m (1 - \frac{n_0}{\theta})^{n-m}$, on obtient finalement: \
$\forall n \in \mathbb{N}, \mathbb{P}(N = m+n) = \begin{pmatrix} m + n-1 \\ m-1\end{pmatrix}(\frac{n_0}{\theta})^m (1 - \frac{n_0}{\theta})^{n}$ \ \\
Ici,\ \\
\includegraphics[scale=0.5]{images/Q2_2.png} \ \\
\end{exo2}

\begin{exo2} \ \\ \\
L'estimateur par la méthode des moments est $\overline{\theta}'_m = n_0 \bar{Y}$\ \\
On cherche à annuler la dérivée de la fonction de vraisemblance $\mathcal{L}$:
\begin{equation}
\begin{aligned}
\mathcal{L}(\theta;y_1,...,y_n) & = \prod_{j=1}^{m}P(Y_j = y_j; \theta) \ \\
& = \prod_{j=1}^{m}(1-\frac{n_0}{\theta})^{y_i - 1}\frac{n_0}{\theta}\ \\
& = (\frac{n_0}{\theta})^{m} \prod_{j=1}^{m} (1-\frac{n_0}{\theta})^{y_i -1} \ \\
\end{aligned}
\end{equation}
On calcule donc $\frac{\partial{\ln{\mathcal{L}}}}{\partial{t}}$ et on cherche ensuite à l'annuler pour maximiser la log-vraisemblance:
\begin{equation}
\begin{aligned}
    \ln{\mathcal{L}}(\theta;y_1,...,y_n) & = m\ln{\frac{n_0}{\theta}} + \sum_{j=1}^{m} (y_i - 1)\ln{1 - \frac{n_0}{\theta}}\ \\
    \frac{\ln{\partial{\mathcal{L}}}}{\partial{\theta}} & = \frac{-m}{\theta} + \sum_{j=1}^{m} (y_i - 1)\frac{-\frac{n_0}{\theta^2}}{1-\frac{n_0}{\theta}} \ \\
    & = \frac{-m}{\theta} - \sum_{j=1}^{m} (y_i - 1)\frac{n_0}{\theta^2-\theta n_0}
\end{aligned}
\end{equation}
Avant simplification, on trouve $\hat{\theta}'_m = n_0 \frac{\sum_{j=1}^{m} (y_i - 1) + m}{m}$, puis le +m au numérateur compense les -1, et on retrouve $\hat{\theta}'_m = n_0 \bar{Y}$ \ \\
Ainsi, pour notre échantillon, nous calculons: \ \\
\includegraphics[scale=0.5]{images/Q2_3.png} \ \\
\end{exo2}

\begin{exo2} \ \\ \\
Les $Y_i$ sont indépendantes et suivent la même loi, on a donc:
\begin{equation}
    \begin{aligned}
    \mathcal{I}_m & = m \mathcal{I}_1 \ \\
    & = m Var(\frac{\partial}{\partial{\theta}} \ln{\mathcal{L}(\theta, Y_1}))\ \\
    & = m Var(\frac{\partial}{\partial{\theta}} [\ln{\frac{n_0}{\theta}] + (Y_1 -1)\ln(1 - \frac{n_0}{\theta}))\ \\
    & = m Var(\frac{-1}{\theta} + (Y_1 -1)\frac{n_0}{\theta^2 - \theta n_0})\ \\
    & = m(\frac{n_0}{\theta^2 - \theta n_0})^2((\frac{\theta}{n_0})^2 - \frac{\theta}{n_0})
    \end{aligned}
\end{equation}
Finalement, $\mathcal{I}_m = \frac{m}{\theta^2 - \theta n_0}$ \ \\
Pour notre échantillon, on obtient \ \\
\includegraphics[scale=0.5]{images/Q2_4.png} \ \\ \\
$\mathbb{E}({\hat{\theta}}'_m) = n_0 \mathbb{E}(\bar{Y}) = \theta$ donc $\hat{\theta}'_m$ est sans biais. À présent, on déduit de l'inégalité FDCR que cet estimateur est de variance minimale si et seulement si sa variance est égale à $\frac{1}{\mathcal{I}_m(\theta)}$, donc égale à $\frac{\theta^2}{m} - \frac{\theta n_0}{m}$.
\begin{equation}
    \begin{aligned}
    Var(\hat{\theta}'_m) & = Var(\frac{n_0}{m} \sum\limits_{j=1}^{m}Y_i)$ (où les $Y_i$ sont indépendantes)$ \ \\
    & = \frac{n_0^2}{m} Var(Y_1)\ \\
    & = \frac{n_0^2}{m} [(\frac{\theta}{n_0})^2 - \frac{\theta}{n_0}] \ \\
    & = \frac{\theta^2}{m} - \frac{\theta n_0}{m}
    \end{aligned}
\end{equation}
${\hat{\theta}}'_m$ est donc effectivement de variance minimale.
\end{exo2}

\begin{exo2}
Le calcul des intervalles de confiance pour notre échantillon donne les résultats suivants: \ \\
\includegraphics[scale=0.5]{images/Q2_5.png} \ \\
On obtient le tableau suivant:\ \\ \\
\begin{tabular}{|c|c|}
    \hline
    \alpha & Intervalle de confiance \\
    \hline
    1\% & $[ 919.5, 1643.0 ]$ \\
    5\% & $[ 1006.0, 1556.5 ]$ \\
    10\% & $[ 1050.3, 1512.2 ]$ \\
    20\% & $[ 1101.3, 1461.2 ]$ \\
    \hline
\end{tabular}
\end{exo2}

\newpage

%======================================
\section{Application et comparaison des stratégies.}
%======================================

\begin{exo3} \ \\ \\
La première stratégie consiste à évaluer le ratio $\frac{Nombre De Poissons Bagues}{Nombre Total De Poissons}$, puis, connaissant le nombre exact de poissons bagués, en déduire une estimation du nombre total de poissons. Sur 1000 poissons pêchés, 35 sont bagués. Il y a donc une proportion $p=\frac{35}{1000}=0.035$ de poissons bagués parmi les poissons pêchés. On peut donc estimer $\theta=0.035$.\newline On calcule les intervalles de confiances :
\begin{enumerate}
    \item Intervalle de confiance exact : $[0.02449753 , 0.02533891]$
    \item Intervalle de confiance asymptotuque de seuil à 5\% : $[0.02544073 , 0.04455927]$
\end{enumerate}
\end{exo3}

\begin{exo3} \ \\ \\
La deuxième stratégie repose sur la supposition suivante : le nombre de poissons pêchés avant de tomber sur un poisson bagué suit une loi géométrique de paramètre $\lambda$ à déterminer. Ce paramètre est le ratio précédent, donc :\newline $\lambda=\frac{Nombre De Poissons Bagues}{Nombre Total De Poissons}$. \newline Donc une estimation de $\lambda$ conduira de façon inévitable à une estimation du ratio. La deuxième stratégie consiste à évaluer $\lambda$. \newline On trouve $\lambda=0.03521127$. Calculons l'intervalle de confiance asymptotique de seuil à 5\% : \newline $[0.00000000, 0.08645611]$
\end{exo3}

\begin{exo3} \ \\ \\
R nous permet de tracer cet histogramme :  \ \\
\begin{figure}[h]
\includegraphics[scale=1.2]{images/Histogramme_de_Y_avec_regroupement.jpeg}
\end{figure} \ \\
Cet histogramme ressemble fort à la représentation d'une variable aléatoire qui suit une loi géométrique. On peut donc considérer que l'hypothèse d'une loi géometrique est vérifiée. En tout cas, elle n'est pas absurde.
\end{exo3}

\begin{exo3} \ \\ \\
Pour décider de la meilleure stratégie, comparons les intervalles de confiance asymptotiques. Intéressons nous plus particulièrement aux longueurs de ces intervalles : 
\begin{enumerate}
    \item Stratégie 1 : 0.01911855
    \item Stratégie 2 : 0.08645611
\end{enumerate}

Il apparaît que la longueur pour la deuxième stratégie est presque 5 fois plus importante que celui de la première stratégie. \newline \newline Il est donc préférable de choisir la première stratégie.
\end{exo3}

\newpage

%======================================
\section{Vérifications expérimentales à base de simulations.}
%======================================

\begin{exo4} \ \\ \\
On calcule en R les différentes proportions d'appartenance de $\theta$ pour les intervalles de confiance établis en variant les paramètres.
\begin{figure}[h]
\includegraphics[scale=0.85]{images/Q4_1_theta.PNG}
\end{figure} \ \\
Lorsqu'on augmente $\theta$, on remarque que la proportion d'appartenance aux intervalles de $\theta$ diminue lorsqu'on choisit l'intervalle de confiance asymptotique. \ \\
En effet, lorsqu'on augmente $\theta$, la probabilité $p$ diminue donc l'intervalle asymptotique a une plus grande probabilité de se "tromper" car le nombre $n$ d'essais n'est pas grand.
\begin{figure}[h]
\includegraphics[scale=0.85]{images/Q4_1_n0.PNG}
\end{figure} \ \\
Lorsqu'on augmente $n_{0}$, on remarque que la proportion d'appartenance augmente très légèrement. \ \\
En effet, comme $n_{0}$ est proportionnel à $p$ et pour la même raison que précédemment, cela paraît cohérent.
\begin{figure}[h]
\includegraphics[scale=0.85]{images/Q4_1_n.PNG}
\end{figure} \ \\
Lorsqu'on augmente $n$, on ne constate pas de changement particulier, ce qui peut paraître incohérent car concernant l'intervalle asymptotique, ce dernier devrait être plus précis lorsque $n$ est grand.
\newpage
\begin{figure}[h]
\includegraphics[scale=0.85]{images/Q4_1_m.PNG}
\end{figure} \ \\
Lorsqu'on augmente $m$, on constate une stabilisation au niveau des proportions donc de la précision des intervalles. \ \\
En effet, augmenter $m$ permet juste de rendre la simulation plus précise puisqu'on se base sur un plus grand nombre d'essais pour établir les proportions.
\begin{figure}[h]
\includegraphics[scale=0.85]{images/Q4_1_alpha.PNG}
\end{figure} \ \\
Lorsqu'on augmente $\alpha$, quel que soit le type d'intervalle (exact ou asymptotique), il est cohérent que la proportion diminue car on baisse le niveau de confiance donc la précision de ces intervalles. \ \\
\end{exo4}

\begin{exo4} \ \\ \\
On simule $m=100$ échantillons de taille $n=5,10,100,1000,10000,100000$ de loi de Bernoulli, puis on compare les m moyennes empiriques avec les espérances (avec une erreur de $\epsilon=0.01$) pour illustrer la loi faible des grands nombres :
\begin{figure}[h]
\includegraphics[scale=1.2]{images/Q4_2.PNG}
\end{figure} \ \\
Lorsque $n$ augmente, on remarque que l'écart entre la moyenne empirique et l'espérance diminue. A partir de $n=1000$ environ, on peut dire que la moyenne empirique peut être approximée par l'espérance. La loi faible des grands nombres est ainsi illustrée.
\end{exo4}

\begin{exo4} \ \\ \\
De la même manière que précédement, on va faire la même simulation avec $m=100$ et en faisant varier $n=5,30,50,100,1000,10000$, sauf qu'on va tracer les histogrammes (de même largeur en l'occurrence) des moyennes empiriques pour chaque valeur de $n$ ainsi que les graphes de probabilités associés pour la loi normale :
\newpage
\begin{figure}[h]
\includegraphics[scale=1]{images/Q4_3_histo.PNG}
\end{figure} \ \\
On remarque que la courbe associée à l'histogramme s'apparente à celle modélisant la fonction de densité de la loi normale à partir de $n=50$ environ.
\begin{figure}[h]
\includegraphics[scale=1]{images/Q4_3_proba.PNG}
\end{figure} \ \\
De même, en traçant les graphes de probabilité $(F_{\mathscr{N}}^{-1}(\overline{x_{i}})$, $F_{\mathscr{N}}^{-1}(\frac{i}{m}))$ où  $\forall i=1,...,n$ $\overline{x_{i}}$ est une des $m$ moyennes empiriques de chaque groupe de n $x_{i}$ (avec les $x_{i}$ qui sont iid et suivent chacune une loi de Bernoulli) de l'échantillon de données. On remarque de même l'apparence d'une droite à partir de $n=50$ ce qui confirme le fait qu'à partir d'une certaine valeur, la moyenne empirique des $x_{i}$ suit une loi normale. Le théorème centrale limite est ainsi illustré.
\end{exo4}

\end{document}


